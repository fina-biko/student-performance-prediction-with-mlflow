

hyperparameters:
  DecisionTree:
    criterion: ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']
    splitter: ['best', 'random']
    max_features: ['sqrt', 'log2']

  #RandomForest:
    #criterion: ['poisson', 'squared_error', 'absolute_error', 'friedman_mse']
   # max_features: ['sqrt', 'log2', None]
    #n_estimators: [8, 16, 32, 64, 128, 256]
    #min_samples_leaf: [1, 2, 4, 8,]

  GradientBoosting : 
    loss : ['squared_error', 'huber', 'absolute_error', 'quantile']
    learning_rate: [.1,.01,.05,.001]
    subsample: [0.6,0.7,0.75,0.8,0.85,0.9]
    criterion: ['squared_error', 'friedman_mse']
    max_features: ['auto','sqrt','log2']
    n_estimators: [8,16,32,64,128,256]

  Linear Regression : {}

  XGBRegressor:
    learning_rate: [.1,.01,.05,.001]
    n_estimators: [8,16,32,64,128,256] 

                   

  AdaBoost Regressor : 
    learning_rate: [.1,.01,0.5,.001]
    loss: ['linear','square','exponential']
    n_estimators: [8,16,32,64,128,256]