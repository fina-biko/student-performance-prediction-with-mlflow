{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''update the config.yaml file\n",
    "the constants will be unchanged\n",
    "update the entity\n",
    "update the configuration manager\n",
    "do the test train split\n",
    "'''\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    raw_data:Path\n",
    "    schema_data:Path\n",
    "    transf_train_set:Path# i need where to store my tranformed train set after splitting,it will be pointing to artifacts.datatransformation folder\n",
    "    transf_test_set:Path\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mlproject.constants import CONFIG_PATH_YAML,SCHEMA_PATH_YAML\n",
    "from src.mlproject.entity.config_entity import DataIngestionConfig\n",
    "from src.mlproject.utils.common import read_yaml,create_directories\n",
    "import os\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,config_filepath=CONFIG_PATH_YAML) :#inner folder,pathto csv,datastore\n",
    "        self.config_data=read_yaml(config_filepath)\n",
    "        self.schema=read_yaml(SCHEMA_PATH_YAML)\n",
    "        '''\n",
    "         #Retrieve the parent folder \n",
    "        self.parent_folder =self.config_data.get('parent_folder', '')\n",
    "         #Retrieve the artifcats root \n",
    "        self.artifacts_root =self.parent_folder.get('artifacts_root', '')\n",
    "        #and create the folder 'artifacts_root'\n",
    "        create_directories([self.artifacts_root])'''\n",
    "\n",
    "        \n",
    "         #DATA TRANSFORMATION\n",
    "        #retrieve the data ttransformation category\n",
    "        self.data_transformation=self.config_data.get('data_transformation','')\n",
    "        #create the folder within it \n",
    "        create_directories([self.data_transformation.get('inner_folder','')])\n",
    "        #join the files\n",
    "        # join the files and assign the result to variables\n",
    "        self.transformed_train_set_path = os.path.join(self.data_transformation.get('inner_folder', ''),self.data_transformation.get('transformed_train_set', ''))\n",
    "        #os.path.join(self.data_transormation.get('inner_folder',''),self.data_transormation.get('transformed_train_set',''))\n",
    "        self.transformed_test_set_path=os.path.join(self.data_transformation.get('inner_folder',''),self.data_transformation.get('transformed_test_set',''))\n",
    "        \n",
    "       \n",
    "       \n",
    "        \n",
    "         \n",
    "       #instantiate the defined entities and return the instance\n",
    "    def get_data_transformation_config(self)->DataTransformationConfig:\n",
    "\n",
    "            data_transformation_config = DataTransformationConfig(\n",
    "                transf_train_set=self.transformed_train_set_path,\n",
    "                transf_test_set=self.transformed_test_set_path,\n",
    "                raw_data=self.data_transformation.get('raw_data',''),\n",
    "                schema_data=self.schema\n",
    "                \n",
    "                \n",
    "                )\n",
    "            \n",
    "            return data_transformation_config\n",
    "    \n",
    "    \n",
    "                \n",
    "            \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "define the categorical columns and numerical columns and the target column\n",
    "split into train and test\n",
    "define the train x and train y,test x and test y\n",
    "define the transformation to be performed on categorical \n",
    "define the transformation to be performed on numerical \n",
    "save the transformation object\n",
    "combine the trainx and train y\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.mlproject.utils.common import read_yaml_keys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "#from scipy.sparse import issparse\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "class DataTransformationEntity:\n",
    "    def __init__(self,config_instance:DataTransformationConfig) :\n",
    "        self.transf_config=config_instance\n",
    "       \n",
    "        \n",
    "        self.test_set_transf=self.transf_config.transf_test_set\n",
    "        self.train_set_transf=self.transf_config.transf_train_set\n",
    "        self.raw_data=self.transf_config.raw_data\n",
    "        self.schemapath=self.transf_config.schema_data\n",
    "\n",
    "    '''def accesss_trans_config_elements(self):\n",
    "        self.transf_train_set=self.transf_config.transf_test_set\n",
    "        self.trans_test_set=self.transf_config.transf_test_set'''\n",
    "    def initiate_split(self):\n",
    "        categorical_col,numerical_cal,target_col=read_yaml_keys(self.transf_config.schema_data)\n",
    "        \n",
    "        raw_data_df=pd.read_csv(self.raw_data)\n",
    "\n",
    "        \n",
    "\n",
    "        train,test=train_test_split(raw_data_df,random_state=42,test_size=0.2)\n",
    "\n",
    "        \n",
    "\n",
    "        train_df=pd.DataFrame(train,columns=raw_data_df.columns)\n",
    "        test_df=pd.DataFrame(test,columns=raw_data_df.columns)\n",
    "\n",
    "        \n",
    "        train_y=train_df[target_col]\n",
    "        \n",
    "        \n",
    "        train_x = train_df.drop(target_col, axis=1)\n",
    "        \n",
    "\n",
    "        test_y=test_df[target_col]\n",
    "        test_x=test_df.drop(target_col,axis=1)\n",
    "       \n",
    "        \n",
    "        return train_x,train_y,test_x,test_y\n",
    "    def transformations(self):\n",
    "        cat_pipeline=Pipeline(\n",
    "            steps=[\n",
    "            #('imputer',SimpleImputer(strategy=\"most_frequent\")),\n",
    "            ('encoder',OneHotEncoder(handle_unknown='ignore')),\n",
    "            ]\n",
    "            )\n",
    "        '''num_pipeline=Pipeline(\n",
    "            steps=[\n",
    "            ('impute',SimpleImputer(strategy='median')),\n",
    "            ('scaler',StandardScaler(with_mean=False))\n",
    "            ]\n",
    "        )'''\n",
    "\n",
    "\n",
    "        num_pipeline = Pipeline(\n",
    "           steps=[\n",
    "          # ('impute', SimpleImputer(strategy='median')),\n",
    "           ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "        return cat_pipeline,num_pipeline\n",
    "    \n",
    "\n",
    "    \n",
    "  \n",
    "    def cols_transformer(self):\n",
    "        categorical_col,numerical_cal,target_col=read_yaml_keys(self.transf_config.schema_data)\n",
    "        train_x,train_y,test_x,test_y=self.initiate_split()\n",
    "\n",
    "        cat_pipe,num_pipe=self.transformations()\n",
    "        \n",
    "        preprocessing_obj=ColumnTransformer(transformers=[('num',num_pipe,numerical_cal),('cat',cat_pipe,categorical_col)],remainder='drop')\n",
    "        # Assuming preprocessing_obj is the ColumnTransformer\n",
    "        \n",
    "        \n",
    "        \n",
    "        return preprocessing_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''the actual transformation\n",
    " as it has all the transformations\n",
    "\n",
    "pass in the entities you need from the the DataTransfofrmationEntity,an instance of the DataTransformationEntity\n",
    " \n",
    "do the actujal transformation using entities from DataTransfofrmationEntity\n",
    "store the transformations in the paths specified by DataTransformationConfig instnce which i put as attributtes of the DataTransformationEntity\n",
    "TRANSFORMATION>PY'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class DataTransformation:\n",
    "    def __init__(self,configEnt:DataTransformationEntity) :\n",
    "        \n",
    "        self.transformation_entity=configEnt#an ins\n",
    "        \n",
    "        \n",
    "    def transformation(self):\n",
    "        categorical_col,numerical_cal,target_col=read_yaml_keys(self.transformation_entity.schemapath)\n",
    "\n",
    "        train_x_transf, train_y, test_x_transf,test_y=self.transformation_entity.initiate_split()\n",
    "        print(test_y)\n",
    "        \n",
    "        self.transformation_entity.transformations()\n",
    "        prep_obj=self.transformation_entity.cols_transformer()\n",
    "\n",
    "        \n",
    "        trainx_transformed_data=prep_obj.fit_transform(train_x_transf)\n",
    "        \n",
    "        # Get feature names after transformation\n",
    "        transformed_feature_names = prep_obj.get_feature_names_out(input_features=categorical_col+ numerical_cal)\n",
    "\n",
    "       # Create a DataFrame with the transformed data and feature names\n",
    "        trainx_transformed_df = pd.DataFrame(trainx_transformed_data, columns=transformed_feature_names)\n",
    "        trainx_transformed_df[target_col]=train_y.values# if forgot the .values so it really was a prob\n",
    "        \n",
    "\n",
    "        \n",
    "       \n",
    "        testx_transformed_data=prep_obj.transform(test_x_transf)\n",
    "        testx_transformed_df = pd.DataFrame(testx_transformed_data, columns=transformed_feature_names)\n",
    "        testx_transformed_df[target_col] = test_y.values  # Use .values to get the underlying NumPy array, if you ommit,you  get values assigned to some records not all\n",
    "        print(testx_transformed_df.head(1))\n",
    "        print(testx_transformed_df.shape)\n",
    "        \n",
    "    \n",
    "\n",
    "       \n",
    "        with open(self.transformation_entity.train_set_transf,'w') as train_csv:\n",
    "           trainx_transformed_df.to_csv(train_csv,index=False)\n",
    "\n",
    "        with open(self.transformation_entity.test_set_transf,'w') as test_csv:\n",
    "            testx_transformed_df.to_csv(test_csv,index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521    91\n",
      "737    53\n",
      "740    80\n",
      "660    74\n",
      "411    84\n",
      "       ..\n",
      "408    52\n",
      "332    62\n",
      "208    74\n",
      "613    65\n",
      "78     61\n",
      "Name: math_score, Length: 200, dtype: int64\n",
      "   num__reading_score  num__writing_score  cat__gender_female  \\\n",
      "0            1.137866            1.031032                 1.0   \n",
      "\n",
      "   cat__gender_male  cat__race_ethnicity_group A  cat__race_ethnicity_group B  \\\n",
      "0               0.0                          0.0                          0.0   \n",
      "\n",
      "   cat__race_ethnicity_group C  cat__race_ethnicity_group D  \\\n",
      "0                          1.0                          0.0   \n",
      "\n",
      "   cat__race_ethnicity_group E  \\\n",
      "0                          0.0   \n",
      "\n",
      "   cat__parental_level_of_education_associate's degree  \\\n",
      "0                                                1.0     \n",
      "\n",
      "   cat__parental_level_of_education_bachelor's degree  \\\n",
      "0                                                0.0    \n",
      "\n",
      "   cat__parental_level_of_education_high school  \\\n",
      "0                                           0.0   \n",
      "\n",
      "   cat__parental_level_of_education_master's degree  \\\n",
      "0                                               0.0   \n",
      "\n",
      "   cat__parental_level_of_education_some college  \\\n",
      "0                                            0.0   \n",
      "\n",
      "   cat__parental_level_of_education_some high school  cat__lunch_free/reduced  \\\n",
      "0                                                0.0                      0.0   \n",
      "\n",
      "   cat__lunch_standard  cat__test_preparation_course_completed  \\\n",
      "0                  1.0                                     0.0   \n",
      "\n",
      "   cat__test_preparation_course_none  math_score  \n",
      "0                                1.0          91  \n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "'''pipeline'''\n",
    "\n",
    "class TransformationPipeline():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        configmanager=ConfigurationManager()\n",
    "        data_config_instance=configmanager.get_data_transformation_config()\n",
    "        entity_instance=DataTransformationEntity(data_config_instance)\n",
    "        data_transf_instance=DataTransformation(entity_instance)\n",
    "        data_transf_instance.transformation()\n",
    "     \n",
    "if __name__=='__main__':\n",
    "   obj=TransformationPipeline()\n",
    "   obj.main()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
